[
    {
        "content": "<p>I just wanted to get some opinion on two different ways <code>example/llm</code> can run:</p>\n<ol>\n<li>The example will pre-load the models and start Open WebUI. This ensures the user can immediately prompt the model once the WebUI launches. But this has a one-time wait period for pulling the model.</li>\n<li>The example will immediately start Open WebUI and the user can load whatever model they want from the “Admin Panel”. </li>\n</ol>\n<p><strong>Try out example1</strong>: <code>nix run github:juspay/services-flake?dir=example/llm —override-input services-flake github:juspay/services-flake</code></p>\n<p><strong>Try out example2</strong>: <code>nix run \"github:drupol/services-flake/fix-open-webui-example?dir=example/llm\" --refresh --override-input services-flake github:juspay/services-flake</code></p>\n<p>PR for example2: <a href=\"https://github.com/juspay/services-flake/pull/227\">https://github.com/juspay/services-flake/pull/227</a></p>",
        "id": 444681833,
        "sender_full_name": "Shivaraj B H",
        "timestamp": 1718365310
    },
    {
        "content": "<p>cc <span class=\"user-mention\" data-user-id=\"678574\">@Andreas</span> who has tried this out before.</p>\n<p>Perhaps we should invite the PR author (<code>drupol</code>) here.</p>",
        "id": 444705489,
        "sender_full_name": "Srid",
        "timestamp": 1718373162
    },
    {
        "content": "<p>I'm fine with pre-loading it. It is just an example, but it is an unique example we are also using it for <em>demo</em> (video).</p>",
        "id": 444705643,
        "sender_full_name": "Srid",
        "timestamp": 1718373208
    },
    {
        "content": "<p>yeah sure, why not invite Drupol!</p>\n<p>I've been debugging ollama on docker anyways the last 2 days. Because the dual GPU stack I run has issues of an unclear nature.</p>",
        "id": 444705811,
        "sender_full_name": "Andreas",
        "timestamp": 1718373252
    },
    {
        "content": "<p>I also like <code>dataDir</code> to remain <code>$HOME/.services-flake/ollama</code>, because then I can always revisit the \"app\" by re-runing <code>nix run ...</code> and play with the model locally. In a way, this example also demonstrates that you can use services-flake not only to run services in development project, but also as an end-user \"app\" (where there's no concept of flake project directory under $HOME, since <code>nix run ...</code> doesn't require it).</p>",
        "id": 444705940,
        "sender_full_name": "Srid",
        "timestamp": 1718373296
    },
    {
        "content": "<p>Hey hi !</p>",
        "id": 444706369,
        "sender_full_name": "Pol Dellaiera",
        "timestamp": 1718373415
    },
    {
        "content": "<p>I'm @drupol on Github.</p>",
        "id": 444706402,
        "sender_full_name": "Pol Dellaiera",
        "timestamp": 1718373423
    },
    {
        "content": "<p>Hey <span class=\"user-mention\" data-user-id=\"728730\">@Pol Dellaiera</span> and welcome!</p>",
        "id": 444706411,
        "sender_full_name": "Andreas",
        "timestamp": 1718373425
    },
    {
        "content": "<p>I joined to discuss about this: <a href=\"https://github.com/juspay/services-flake/pull/227#issuecomment-2168096533\">https://github.com/juspay/services-flake/pull/227#issuecomment-2168096533</a></p>",
        "id": 444706541,
        "sender_full_name": "Pol Dellaiera",
        "timestamp": 1718373470
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"667408\">@Srid</span> Hey I'm here :)</p>",
        "id": 444706643,
        "sender_full_name": "Pol Dellaiera",
        "timestamp": 1718373495
    },
    {
        "content": "<p>Welcome :-)</p>",
        "id": 444706855,
        "sender_full_name": "Srid",
        "timestamp": 1718373558
    },
    {
        "content": "<p>(I posted about the formatter in <a class=\"stream\" data-stream-id=\"413950\" href=\"/#narrow/stream/413950-nix\">#nix</a> )</p>",
        "id": 444706914,
        "sender_full_name": "Srid",
        "timestamp": 1718373578
    },
    {
        "content": "<p>How about finding a compromise?</p>\n<p>services-flake is great because it can save data in the same user directory where the flake.nix belong. Maybe we should establish some kind of <code>./data</code> directory that is always there (equivalent to the <code>./state</code> directory in direnv) and add a comment explaining that user is free to change that directory?</p>\n<p>Hiding the ollama LLMs under <code>$home/.service-flake/</code> is definitely too intrusive for me already.</p>",
        "id": 444708159,
        "sender_full_name": "Pol Dellaiera",
        "timestamp": 1718373930
    },
    {
        "content": "<p>How are you using <code>example/llm</code> for your use case? As an actual app seeing everyday use?</p>",
        "id": 444708403,
        "sender_full_name": "Srid",
        "timestamp": 1718373994
    },
    {
        "content": "<p>No, I use the NixOS service on my side, but I have plenty of colleagues I wish I could show the demo. But Nix is already quite magical for a lot of people and I think it's a good idea to make things clear by not hiding where the files are going to be saved by default.</p>",
        "id": 444708567,
        "sender_full_name": "Pol Dellaiera",
        "timestamp": 1718374046
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"728730\">Pol Dellaiera</span> <a href=\"#narrow/stream/414011-services-flake/topic/Require.20opinion.20on.20.60example.2Fllm.60/near/444708567\">said</a>:</p>\n<blockquote>\n<p>Nix is already quite magical for a lot of people and I think it's a good idea to make things clear by not hiding where the files are going to be saved by default.</p>\n</blockquote>\n<p>Okay, fair enough. I'm happy with using default <code>dataDir</code> then.</p>",
        "id": 444708826,
        "sender_full_name": "Srid",
        "timestamp": 1718374118
    },
    {
        "content": "<p>Cool, thanks ! :) Do you want me to add a comment in the flake for <code>dataDir</code> ?</p>",
        "id": 444708902,
        "sender_full_name": "Pol Dellaiera",
        "timestamp": 1718374145
    },
    {
        "content": "<p>Instead of removing it, you could just comment out <code># dataDir = ...</code></p>",
        "id": 444709042,
        "sender_full_name": "Srid",
        "timestamp": 1718374200
    },
    {
        "content": "<p>yeah I was about to do that.</p>",
        "id": 444709136,
        "sender_full_name": "Pol Dellaiera",
        "timestamp": 1718374216
    },
    {
        "content": "<p>Also, I still like pre-loading models, so restore <code>models = [ \"llama2-uncensored\" ];</code> as well.</p>",
        "id": 444709202,
        "sender_full_name": "Srid",
        "timestamp": 1718374239
    },
    {
        "content": "<p>Sad. I would prefer to start with no LLM so users are free to use whatever they want.</p>",
        "id": 444709379,
        "sender_full_name": "Pol Dellaiera",
        "timestamp": 1718374290
    },
    {
        "content": "<p>And starting with <code>llama2-uncensored</code> is... meh.</p>",
        "id": 444709422,
        "sender_full_name": "Pol Dellaiera",
        "timestamp": 1718374303
    },
    {
        "content": "<p>I mainly want the <code>nix run ...</code> invocation for this example to work 'out of the box' (with little manual poking) as much as possible. I have no preference on the specific model (smaller is generally better)</p>",
        "id": 444709658,
        "sender_full_name": "Srid",
        "timestamp": 1718374372
    },
    {
        "content": "<p>I mean nowadays we could go llama3 ... or which one would you prefer?</p>",
        "id": 444709699,
        "sender_full_name": "Andreas",
        "timestamp": 1718374383
    },
    {
        "content": "<p>IMHO - I would not force users to download 4+GB of models on their behalv. I would leave it empty.</p>",
        "id": 444709774,
        "sender_full_name": "Pol Dellaiera",
        "timestamp": 1718374416
    },
    {
        "content": "<p>How about a middle ground? use <code>tinydolphin</code> as the default pre-loaded model, for the purpose of the user to quickly verify if they are able to prompt and get a response. After which they are free to pull whatever model they want from the Admin panel?</p>",
        "id": 444709948,
        "sender_full_name": "Shivaraj B H",
        "timestamp": 1718374465
    },
    {
        "content": "<p>How big is <code>tinydolphin</code>?</p>",
        "id": 444710106,
        "sender_full_name": "Srid",
        "timestamp": 1718374512
    },
    {
        "content": "<p>637 MB it seems</p>",
        "id": 444710156,
        "sender_full_name": "Andreas",
        "timestamp": 1718374532
    },
    {
        "content": "<p>which means it will run on almost any GPU that is supported, which is nice</p>",
        "id": 444710326,
        "sender_full_name": "Andreas",
        "timestamp": 1718374587
    },
    {
        "content": "<p>so, <code>tinydolphin</code> ?</p>",
        "id": 444710570,
        "sender_full_name": "Pol Dellaiera",
        "timestamp": 1718374680
    },
    {
        "content": "<p>I propose this then,</p>\n<p>Have two examples,</p>\n<ul>\n<li><code>examples/ollama-ui</code>: basically our current example but with all of <span class=\"user-mention\" data-user-id=\"728730\">@Pol Dellaiera</span> 's suggestions (no custom dataDir; no pre-loaded models)</li>\n<li><code>examples/llm</code>: a new example that <code>import</code>s the previous example (shared service) and sets the two things only -- <code>dataDir</code> and <code>models</code> (here, we can use a good model without size restriction)</li>\n</ul>\n<p>For video demo (on X and for docs), we can use the latter example.</p>",
        "id": 444710764,
        "sender_full_name": "Srid",
        "timestamp": 1718374732
    },
    {
        "content": "<p>The later can also serve as a demonstration of sharing of services.</p>",
        "id": 444710875,
        "sender_full_name": "Srid",
        "timestamp": 1718374763
    },
    {
        "content": "<p>As you wish guys... this is your project :)</p>",
        "id": 444711152,
        "sender_full_name": "Pol Dellaiera",
        "timestamp": 1718374848
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"667408\">Srid</span> <a href=\"#narrow/stream/414011-services-flake/topic/Require.20opinion.20on.20.60example.2Fllm.60/near/444710764\">said</a>:</p>\n<blockquote>\n<p>For video demo (on X and for docs), we can use the latter example.</p>\n</blockquote>\n<p>And in future, we can tell people \"if you want to see what services-flake can do, run <code>nix run ...</code>\" (pointing to this latter example)</p>",
        "id": 444711183,
        "sender_full_name": "Srid",
        "timestamp": 1718374854
    },
    {
        "content": "<p>perhaps choose a slightly more specific name for <code>examples/llm</code>... idk what you guys typically go for, <code>examples/ollama-preloaded</code> maybe?</p>",
        "id": 444711211,
        "sender_full_name": "Andreas",
        "timestamp": 1718374861
    },
    {
        "content": "<p>Yea, good idea</p>",
        "id": 444711261,
        "sender_full_name": "Srid",
        "timestamp": 1718374871
    },
    {
        "content": "<p>By the way, how do you manage to not use <code>--impure</code> and write in the current directory? What's the magic trick ?</p>",
        "id": 444711286,
        "sender_full_name": "Pol Dellaiera",
        "timestamp": 1718374877
    },
    {
        "content": "<p>Cool, I will merge <span class=\"user-mention\" data-user-id=\"728730\">@Pol Dellaiera</span> ’s PR once the <code>models</code> is removed to demonstrate only the <code>open-webui</code>. I will rename the <code>example/llm</code> to <code>example/open-webui</code> in a different PR. And then add <code>example/ollama-preloaded</code> in another one.</p>\n<p>Sounds good?</p>",
        "id": 444712275,
        "sender_full_name": "Shivaraj B H",
        "timestamp": 1718375171
    },
    {
        "content": "<p>Done.</p>",
        "id": 444712464,
        "sender_full_name": "Pol Dellaiera",
        "timestamp": 1718375238
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"728730\">Pol Dellaiera</span> <a href=\"#narrow/stream/414011-services-flake/topic/Require.20opinion.20on.20.60example.2Fllm.60/near/444711286\">said</a>:</p>\n<blockquote>\n<p>By the way, how do you manage to not use <code>--impure</code> and write in the current directory? What's the magic trick ?</p>\n</blockquote>\n<p><code>nix run</code> doesn’t require pure evaluation mode</p>",
        "id": 444713027,
        "sender_full_name": "Shivaraj B H",
        "timestamp": 1718375422
    }
]